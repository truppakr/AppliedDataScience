{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display first 50 words from file:\n",
      "['three', 'calgarians', 'have', 'found', 'a', 'rather', 'unusual', 'way', 'of', 'leaving', 'snow', 'and', 'ice', 'behind', '.', 'they', 'set', 'off', 'this', 'week', 'on', 'foot', 'and', 'by', 'camel', 'on', 'a', 'grueling', 'trek', 'across', 'the', 'burning', 'arabian', 'desert', '.', 'when', 'they', 'were', 'still', 'in', 'canada', ',', 'planning', 'their', 'trip', ',', 'they', 'expected', 'they', 'would']\n",
      "Display first 50 Stopwords:\n",
      "['â€™s', 'a', \"a's\", 'able', 'about', 'above', 'according', 'accordingly', 'across', 'actually', 'after', 'afterwards', 'again', 'against', \"ain't\", 'all', 'allow', 'allows', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'an', 'and', 'another', 'any', 'anybody', 'anyhow', 'anyone', 'anything', 'anyway', 'anyways', 'anywhere', 'apart', 'appear', 'appreciate', 'appropriate', 'are', \"aren't\", 'around', 'as', 'aside', 'ask', 'asking']\n",
      "\n",
      "Bigrams from file with top 50 frequencies\n",
      "(('mr.', 'clarke'), 0.008797653958944282)\n",
      "(('mr.', 'thesiger'), 0.004398826979472141)\n",
      "(('bedouin', 'people'), 0.002932551319648094)\n",
      "(('degrees', 'celsius'), 0.002932551319648094)\n",
      "(('saudi', 'arabia'), 0.002932551319648094)\n",
      "(('thesiger', \"'s\"), 0.002932551319648094)\n",
      "((\"'m\", 'keen'), 0.001466275659824047)\n",
      "((\"'s\", 'book'), 0.001466275659824047)\n",
      "((\"'s\", 'camp'), 0.001466275659824047)\n",
      "((\"'s\", 'incredible'), 0.001466275659824047)\n",
      "((\"'s\", 'largest'), 0.001466275659824047)\n",
      "((\"'s\", 'words'), 0.001466275659824047)\n",
      "(('185-mile', 'stretch'), 0.001466275659824047)\n",
      "(('abu', 'dhabi'), 0.001466275659824047)\n",
      "(('adventurer', 'sir'), 0.001466275659824047)\n",
      "(('adventurers', 'expect'), 0.001466275659824047)\n",
      "(('al', 'samim'), 0.001466275659824047)\n",
      "(('al', 'shaiba'), 0.001466275659824047)\n",
      "(('arab', 'emirates'), 0.001466275659824047)\n",
      "(('arabian', 'desert'), 0.001466275659824047)\n",
      "\n",
      "Bigrams from file with top 50 mutual information scores\n",
      "(('mr.', 'clarke'), 5.828665428303019)\n",
      "(('mr.', 'thesiger'), 5.506737333415656)\n",
      "['older', 'brother', 'leigh', 'and', 'their', 'friend', 'bruce', 'kirby', '.', 'they', 'have', 'hired', 'three', 'guides', '.', 'they', 'are', 'now', 'in', 'the', 'omani', 'city', 'of', 'solalah', 'on', 'the', 'arabian', 'sea', '.', 'the', 'group', 'was', 'forced', 'to', 'return', 'briefly', 'to', 'replace', 'some', 'broken', 'equipment', ',', 'notably', 'camel', 'saddles', ',', '40', 'kilometres', 'into', 'the']\n",
      "['older', 'brother', 'leigh', 'and', 'their', 'friend', 'bruce', 'kirbi', '.', 'they', 'have', 'hire', 'three', 'guid', '.', 'they', 'are', 'now', 'in', 'the', 'omani', 'citi', 'of', 'solalah', 'on', 'the', 'arabian', 'sea', '.', 'the', 'group', 'wa', 'forc', 'to', 'return', 'briefli', 'to', 'replac', 'some', 'broken', 'equip', ',', 'notabl', 'camel', 'saddl', ',', '40', 'kilometr', 'into', 'the']\n",
      "['old', 'broth', 'leigh', 'and', 'their', 'friend', 'bruc', 'kirby', '.', 'they', 'hav', 'hir', 'three', 'guid', '.', 'they', 'ar', 'now', 'in', 'the', 'oman', 'city', 'of', 'solalah', 'on', 'the', 'arab', 'sea', '.', 'the', 'group', 'was', 'forc', 'to', 'return', 'brief', 'to', 'replac', 'som', 'brok', 'equip', ',', 'not', 'camel', 'saddl', ',', '40', 'kilomet', 'into', 'the']\n",
      "['Stemmed on lancaster but not on porter', 'Stemmed on lancaster but not on porter', 'No stemming on both porter and lancaster', 'No stemming on both porter and lancaster', 'No stemming on both porter and lancaster', 'No stemming on both porter and lancaster', 'Stemmed on lancaster but not on porter', 'Stemmed on porter but not on lancaster', 'No stemming on both porter and lancaster', 'No stemming on both porter and lancaster', 'Stemmed on lancaster but not on porter', 'Stemming is different in porter and lancaster', 'No stemming on both porter and lancaster', 'Stemming is same in porter and lancaster', 'No stemming on both porter and lancaster', 'No stemming on both porter and lancaster', 'Stemmed on lancaster but not on porter', 'No stemming on both porter and lancaster', 'No stemming on both porter and lancaster', 'No stemming on both porter and lancaster', 'Stemmed on lancaster but not on porter', 'Stemmed on porter but not on lancaster', 'No stemming on both porter and lancaster', 'No stemming on both porter and lancaster', 'No stemming on both porter and lancaster', 'No stemming on both porter and lancaster', 'Stemmed on lancaster but not on porter', 'No stemming on both porter and lancaster', 'No stemming on both porter and lancaster', 'No stemming on both porter and lancaster', 'No stemming on both porter and lancaster', 'Stemmed on porter but not on lancaster', 'Stemming is same in porter and lancaster', 'No stemming on both porter and lancaster', 'No stemming on both porter and lancaster', 'Stemming is different in porter and lancaster', 'No stemming on both porter and lancaster', 'Stemming is same in porter and lancaster', 'Stemmed on lancaster but not on porter', 'Stemmed on lancaster but not on porter', 'Stemming is same in porter and lancaster', 'No stemming on both porter and lancaster', 'Stemming is different in porter and lancaster', 'No stemming on both porter and lancaster', 'Stemming is same in porter and lancaster', 'No stemming on both porter and lancaster', 'No stemming on both porter and lancaster', 'Stemming is different in porter and lancaster', 'No stemming on both porter and lancaster', 'No stemming on both porter and lancaster']\n",
      "     filewords porter_stem_words lancaster_stem_words  \\\n",
      "0        older             older                  old   \n",
      "1      brother           brother                broth   \n",
      "2        leigh             leigh                leigh   \n",
      "3          and               and                  and   \n",
      "4        their             their                their   \n",
      "5       friend            friend               friend   \n",
      "6        bruce             bruce                 bruc   \n",
      "7        kirby             kirbi                kirby   \n",
      "8            .                 .                    .   \n",
      "9         they              they                 they   \n",
      "10        have              have                  hav   \n",
      "11       hired              hire                  hir   \n",
      "12       three             three                three   \n",
      "13      guides              guid                 guid   \n",
      "14           .                 .                    .   \n",
      "15        they              they                 they   \n",
      "16         are               are                   ar   \n",
      "17         now               now                  now   \n",
      "18          in                in                   in   \n",
      "19         the               the                  the   \n",
      "20       omani             omani                 oman   \n",
      "21        city              citi                 city   \n",
      "22          of                of                   of   \n",
      "23     solalah           solalah              solalah   \n",
      "24          on                on                   on   \n",
      "25         the               the                  the   \n",
      "26     arabian           arabian                 arab   \n",
      "27         sea               sea                  sea   \n",
      "28           .                 .                    .   \n",
      "29         the               the                  the   \n",
      "30       group             group                group   \n",
      "31         was                wa                  was   \n",
      "32      forced              forc                 forc   \n",
      "33          to                to                   to   \n",
      "34      return            return               return   \n",
      "35     briefly           briefli                brief   \n",
      "36          to                to                   to   \n",
      "37     replace            replac               replac   \n",
      "38        some              some                  som   \n",
      "39      broken            broken                 brok   \n",
      "40   equipment             equip                equip   \n",
      "41           ,                 ,                    ,   \n",
      "42     notably            notabl                  not   \n",
      "43       camel             camel                camel   \n",
      "44     saddles             saddl                saddl   \n",
      "45           ,                 ,                    ,   \n",
      "46          40                40                   40   \n",
      "47  kilometres          kilometr              kilomet   \n",
      "48        into              into                 into   \n",
      "49         the               the                  the   \n",
      "\n",
      "                                           result  \n",
      "0          Stemmed on lancaster but not on porter  \n",
      "1          Stemmed on lancaster but not on porter  \n",
      "2        No stemming on both porter and lancaster  \n",
      "3        No stemming on both porter and lancaster  \n",
      "4        No stemming on both porter and lancaster  \n",
      "5        No stemming on both porter and lancaster  \n",
      "6          Stemmed on lancaster but not on porter  \n",
      "7          Stemmed on porter but not on lancaster  \n",
      "8        No stemming on both porter and lancaster  \n",
      "9        No stemming on both porter and lancaster  \n",
      "10         Stemmed on lancaster but not on porter  \n",
      "11  Stemming is different in porter and lancaster  \n",
      "12       No stemming on both porter and lancaster  \n",
      "13       Stemming is same in porter and lancaster  \n",
      "14       No stemming on both porter and lancaster  \n",
      "15       No stemming on both porter and lancaster  \n",
      "16         Stemmed on lancaster but not on porter  \n",
      "17       No stemming on both porter and lancaster  \n",
      "18       No stemming on both porter and lancaster  \n",
      "19       No stemming on both porter and lancaster  \n",
      "20         Stemmed on lancaster but not on porter  \n",
      "21         Stemmed on porter but not on lancaster  \n",
      "22       No stemming on both porter and lancaster  \n",
      "23       No stemming on both porter and lancaster  \n",
      "24       No stemming on both porter and lancaster  \n",
      "25       No stemming on both porter and lancaster  \n",
      "26         Stemmed on lancaster but not on porter  \n",
      "27       No stemming on both porter and lancaster  \n",
      "28       No stemming on both porter and lancaster  \n",
      "29       No stemming on both porter and lancaster  \n",
      "30       No stemming on both porter and lancaster  \n",
      "31         Stemmed on porter but not on lancaster  \n",
      "32       Stemming is same in porter and lancaster  \n",
      "33       No stemming on both porter and lancaster  \n",
      "34       No stemming on both porter and lancaster  \n",
      "35  Stemming is different in porter and lancaster  \n",
      "36       No stemming on both porter and lancaster  \n",
      "37       Stemming is same in porter and lancaster  \n",
      "38         Stemmed on lancaster but not on porter  \n",
      "39         Stemmed on lancaster but not on porter  \n",
      "40       Stemming is same in porter and lancaster  \n",
      "41       No stemming on both porter and lancaster  \n",
      "42  Stemming is different in porter and lancaster  \n",
      "43       No stemming on both porter and lancaster  \n",
      "44       Stemming is same in porter and lancaster  \n",
      "45       No stemming on both porter and lancaster  \n",
      "46       No stemming on both porter and lancaster  \n",
      "47  Stemming is different in porter and lancaster  \n",
      "48       No stemming on both porter and lancaster  \n",
      "49       No stemming on both porter and lancaster  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\tThis program reads and processes text from a file.\n",
    "\tTo change the file, change the filepath variable\n",
    "\tIt also reads a custom stopword file called Smart.English.stop\n",
    "\tThe program gets the raw text, tokenizes and lowercases the tokens.\n",
    "\tIt puts the tokens in a frequency distribution and displays the 30 most frequent.\n",
    "'''\n",
    "# open python and nltk packages needed for processing\n",
    "import nltk\n",
    "import re\n",
    "from nltk.collocations import *\n",
    "import pandas as pd\n",
    "# put the full path to the file here (or can use relative path from the directory of the program)\n",
    "#filepath = '/Users/njmccrac/NLPfall2016/labs/LabExamplesWeek4/CrimeAndPunishment.txt'\n",
    "#filepath = 'H:\\NLPclass\\LabExamplesWeek4\\CrimeAndPunishment.txt'\n",
    "#filepath = 'C:\\\\Users\\\\rkrishnan\\\\Documents\\\\01 Personal\\\\MS\\\\IST664\\\\Week3\\\\CrimeAndPunishment.txt'\n",
    "filepath = 'C:\\\\Users\\\\rkrishnan\\\\Documents\\\\01 Personal\\\\MS\\\\IST664\\\\Week3\\\\desert.txt'\n",
    "\n",
    "def alpha_filter(w):\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "  pattern = re.compile('^[^a-z]+$')\n",
    "  if (pattern.match(w)):\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "# open the file, read the text and close it\n",
    "f = open(filepath, 'r')\n",
    "filetext = f.read()\n",
    "f.close()\n",
    "\n",
    "len(filetext)\n",
    "# tokenize by the regular word tokenizer\n",
    "filetokens = nltk.word_tokenize(filetext)\n",
    "len(filetokens)\n",
    "# choose to treat upper and lower case the same\n",
    "#    by putting all tokens in lower case\n",
    "filewords = [w.lower() for w in filetokens]\n",
    "\n",
    "\n",
    "# display the first words\n",
    "print (\"Display first 50 words from file:\")\n",
    "print (filewords[:50])\n",
    "\n",
    "# read a stop word file\n",
    "fstop = open('C:\\\\Users\\\\rkrishnan\\\\Documents\\\\01 Personal\\\\MS\\\\IST664\\\\Week3\\\\Smart.English.stop', 'r')\n",
    "stoptext = fstop.read()\n",
    "fstop.close()\n",
    "\n",
    "stopwords = nltk.word_tokenize(stoptext)\n",
    "print (\"Display first 50 Stopwords:\")\n",
    "print (stopwords[:50])\n",
    "\n",
    "# setup to process bigrams\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "       \n",
    "finder = BigramCollocationFinder.from_words(filewords)\n",
    "# choose to use both the non-alpha word filter and a stopwords filter\n",
    "finder.apply_word_filter(alpha_filter)\n",
    "finder.apply_word_filter(lambda w: w in stopwords)\n",
    "\n",
    "# score by frequency and display the top 50 bigrams\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "print ()\n",
    "print (\"Bigrams from file with top 50 frequencies\")\n",
    "for item in scored[:20]:\n",
    "        print (item)\n",
    "\n",
    "# score by PMI and display the top 50 bigrams\n",
    "# only use frequently occurring words in mutual information\n",
    "finder.apply_freq_filter(5)\n",
    "scored = finder.score_ngrams(bigram_measures.pmi)\n",
    "\n",
    "print (\"\\nBigrams from file with top 50 mutual information scores\")\n",
    "for item in scored[:20]:\n",
    "        print (item)\n",
    "\n",
    "\n",
    "porter=nltk.PorterStemmer()\n",
    "lancaster=nltk.LancasterStemmer()\n",
    "\n",
    "\n",
    "# stem file words using porter and lancaster stemmer \n",
    "print(filewords[100:150])\n",
    "\n",
    "porter_stem_words=[porter.stem(w) for w in filewords]\n",
    "print(porter_stem_words[100:150])\n",
    "\n",
    "lancaster_stem_words=[lancaster.stem(w) for w in filewords]\n",
    "print(lancaster_stem_words[100:150])\n",
    "\n",
    "\n",
    "def compare_stems(filewords,porter_stem_words,lancaster_stem_words):\n",
    "    result=[]\n",
    "    result_dict={}\n",
    "    for idx,w in enumerate(filewords):\n",
    "        if w!=porter_stem_words[idx] and w!=lancaster_stem_words[idx] and porter_stem_words[idx]==lancaster_stem_words[idx]:\n",
    "            result.append(\"Stemming is same in porter and lancaster\")\n",
    "        elif w!=porter_stem_words[idx] and w!=lancaster_stem_words[idx] and porter_stem_words[idx]!=lancaster_stem_words[idx]:\n",
    "            result.append(\"Stemming is different in porter and lancaster\")\n",
    "        elif w==porter_stem_words[idx] and w==lancaster_stem_words[idx]:\n",
    "            result.append(\"No stemming on both porter and lancaster\")\n",
    "        elif w==porter_stem_words[idx] and w!=lancaster_stem_words[idx]:\n",
    "            result.append(\"Stemmed on lancaster but not on porter\")\n",
    "        elif w!=porter_stem_words[idx] and w==lancaster_stem_words[idx]:\n",
    "            result.append(\"Stemmed on porter but not on lancaster\")\n",
    "        else:\n",
    "            result.append(\"No result\")\n",
    "    result_dict={'filewords':filewords,'porter_stem_words':porter_stem_words,'lancaster_stem_words':lancaster_stem_words,'result':result}\n",
    "    return result,result_dict\n",
    "    \n",
    "    \n",
    "stem_result,result_dict =compare_stems(filewords[100:150],porter_stem_words[100:150],lancaster_stem_words[100:150])\n",
    "print(stem_result)\n",
    "\n",
    "result_df=pd.DataFrame(result_dict)\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr.\n",
      "Black\n",
      "and\n",
      "Mrs.\n",
      "Brown\n",
      "attended\n",
      "the\n",
      "lecture\n",
      "by\n",
      "Dr.\n",
      "Gray\n",
      "in\n",
      "U.S.A.\n",
      "in-house\n",
      "but\n",
      "Gov.\n",
      "White\n",
      "wasn’t\n",
      "there\n",
      "cost\n",
      "of\n",
      "$15.12\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "ptoken = re.compile(r'''(\n",
    "(?:(?:[A-Z]\\.)+) # abbreviations, e.g. U.S.A.\n",
    "|(?:(?:(?:M|D|Gov)(?:r|rs)?\\.)+) # Mr. Mrs. Dr. Gov.\n",
    "| (?:\\w+(?:[’-]\\w+)*)    # words with internal hyphens\n",
    "| (?:\\$?\\d+(?:\\.\\d+)?)# currency, like $12.40\n",
    ")''', re.X)          # verbose flag\n",
    "shorttext='Mr. Black and Mrs. Brown attended the lecture by Dr. Gray in U.S.A. in-house , but Gov. White wasn’t there. cost of $15.12 '\n",
    "matches=re.findall(ptoken,shorttext)\n",
    "\n",
    "for m in matches:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
